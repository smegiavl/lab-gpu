{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454c61ba-825d-4290-b7ed-135a775fe002",
   "metadata": {},
   "source": [
    "### Numpy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42380e6-436a-4cb5-b45f-a205df14a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRADA DE DATOS POR SBATCH\n",
    "import sys\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    n = int(sys.argv[1])\n",
    "else:\n",
    "    print (\"Debe introducir un valor entero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8019c56a-e5ce-469b-a406-9c6056ab9c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06 s ± 5.51 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
      "Result shape: (7000, 7000)\n",
      "Result type: float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: Large matrices (adjust size as needed)\n",
    "#n = 7000  # For very large matrices, ensure you have enough RAM\n",
    "A = np.random.rand(n, n).astype(np.float32)\n",
    "B = np.random.rand(n, n).astype(np.float32)\n",
    "\n",
    "C = np.dot(A, B)  # warm-up and Matrix multiplication\n",
    "\n",
    "%timeit -r 2 -o np.dot(A, B)\n",
    "\n",
    "print(f\"Result shape: {C.shape}\")\n",
    "print(f\"Result type: {C.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce74f03-ede5-4134-a5de-73549d825393",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f9a54b-6be9-46b9-99fc-a1190e3d93d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.13/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GeForce GTX 1080 which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.13/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
      "/usr/local/lib/python3.13/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
      "NVIDIA GeForce GTX 1080 with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
      "If you want to use the NVIDIA GeForce GTX 1080 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nSearch for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m n = \u001b[32m7000\u001b[39m  \u001b[38;5;66;03m# Establecemos el tamaño de la matriz\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Generamos las matrices en GPU\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m A_torch = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m B_torch = torch.rand((n, n), dtype=torch.float32, device=device)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Hacemos la multiplicación de matrices y precompilado\u001b[39;00m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: no kernel image is available for execution on the device\nSearch for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# Comprobamos que haya una GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Example: Large matrices (adjust size as needed)\n",
    "# n = 7000  # Establecemos el tamaño de la matriz\n",
    "# Generamos las matrices en GPU\n",
    "A_torch = torch.rand((n, n), dtype=torch.float32, device=device)\n",
    "B_torch = torch.rand((n, n), dtype=torch.float32, device=device)\n",
    "\n",
    "# Hacemos la multiplicación de matrices y precompilado\n",
    "C_torch = torch.matmul(A_torch, B_torch)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "def matmul_torch(A,B):\n",
    "    C = torch.matmul(A, B)\n",
    "    if device.type == \"cuda\" :\n",
    "        torch.cuda.synchronize() #Asegurar que se sincroniza\n",
    "    return C\n",
    "\n",
    "## Calculamos tiempo\n",
    "\n",
    "%timeit -r 3 -n 3 matmul_torch(A_torch, B_torch)\n",
    "\n",
    "C_result = matmul_torch(A_torch, B_torch)\n",
    "print(f\"Result shape: {C_result.shape}\")\n",
    "print(f\"Result type: {C_result.dtype}\")\n",
    "#print(C_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc80d9-eba4-467b-8396-b295d6491558",
   "metadata": {},
   "source": [
    "### RESULTADOS OBTENIDOS (n = 7000)\n",
    "#### NUMPY\n",
    "\n",
    "530 ms ± 589 μs per loop (mean ± std. dev. of 2 runs, 100 loops each)\n",
    "\n",
    "Result shape: (1000, 1000)\n",
    "\n",
    "Result type: float32\n",
    "\n",
    "\n",
    "#### PYTORCH\n",
    "557 ms ± 6.12 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
    "\n",
    "Result shape: torch.Size([1000, 1000])\n",
    "\n",
    "Result type: torch.float32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febe0a9-ecd1-4bf2-b2ff-8cc556585dbd",
   "metadata": {},
   "source": [
    "Cuando estudiamos la comparativa, vemos que Pytorch es incluso más lento que Numpy. Esto se debe a que se trata de una matriz de tamaño moderado, lo cual hace que el tiempo de la transferencia de datos pueda ser hasta mayor que el propio cálculo en la GPU.\n",
    "\n",
    "Si se estudiase con matrices de mayor tamaño, quizá Pytorch alcanzaría tiempos menores que Numpy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
